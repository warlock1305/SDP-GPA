## REFERENCES

### Research and Models

- Vaswani, A., et al. 2017. “Attention Is All You Need.” Advances in Neural Information Processing Systems (NeurIPS).

- Feng, Z., et al. 2020. “CodeBERT: A Pre-Trained Model for Programming and Natural Languages.” Findings of EMNLP.

- Alon, U., et al. 2019. “code2seq: Generating Sequences from Structured Representations of Code.” ICLR.

- Breiman, L. 2001. “Random Forests.” Machine Learning 45(1): 5–32.

- Gamma, E., Helm, R., Johnson, R., Vlissides, J. 1994. “Design Patterns: Elements of Reusable Object-Oriented Software.” Addison-Wesley.


### Tools, Libraries, and Runtimes

- Python: https://www.python.org/
- NumPy: Harris, C. R., et al. 2020. Nature 585, 357–362.
- pandas: McKinney, W. 2010. PyData SciPy Conference.
- scikit-learn: Pedregosa, F., et al. 2011. JMLR 12, 2825–2830.
- PyYAML: https://pyyaml.org/
- Requests: https://requests.readthedocs.io/
- PyTorch: Paszke, A., et al. 2019. NeurIPS.
- Transformers: Wolf, T., et al. 2020. EMNLP Demos.
- Streamlit: https://streamlit.io/
- PyArrow: https://arrow.apache.org/
- Git: https://git-scm.com/
- Java (JDK 11+): https://openjdk.org/
- AstMiner: https://github.com/athenarc/astminer (bundled under astminer-0.9.0/)


### APIs and Services

- Hugging Face Model Hub: `microsoft/codebert-base` — https://huggingface.co/microsoft/codebert-base
- GitHub REST API (repos/archives): https://docs.github.com/rest
- GitHub Codeload: https://codeload.github.com/


### Project-Specific Artifacts

- CRAv4 Analyzer: `scripts/analysis/comprehensive_repository_analyzer_v4.py`
- Streamlit Web UI: `scripts/webui/`
- Design-Pattern Detector: `d_p_det/`


### Citation Notes

- Cite CodeBERT (Feng et al., 2020) and Transformers (Wolf et al., 2020) for semantic embeddings.
- Cite AstMiner and code2seq (Alon et al., 2019) for AST path-context extraction.
- Cite Random Forest (Breiman, 2001) for ensemble baselines.
- Cite Streamlit and GitHub/HF Hub for the web UI and external runtime services.


